{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-09T17:45:29.869838Z",
     "start_time": "2024-10-09T17:45:29.842134Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Data handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import kaleido\n",
    "import ipywidgets as widgets\n",
    "from plotly.subplots import make_subplots\n",
    "from IPython.display import display, Image\n",
    "\n",
    "# Statistical analysis\n",
    "from scipy.stats import boxcox, skew\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# ML libraries and utilities\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "# Hyperparameter tuning\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "import logging\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Overview"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ebbae807290728be"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNUT data:\n",
      "        Date       Open       High    Low      Close  Adj Close    Volume  \\\n",
      "0 2021-07-01  16.299999  21.690001  15.50  21.000000  20.361467  40888200   \n",
      "1 2021-07-02  19.854000  20.450001  18.32  19.120001  18.538637   8631400   \n",
      "2 2021-07-06  18.900000  19.120001  17.00  17.000000  16.483095   3973000   \n",
      "3 2021-07-07  17.289000  18.160000  17.00  17.780001  17.239378   3213500   \n",
      "4 2021-07-08  17.250000  18.350000  17.00  18.200001  17.646606   5448300   \n",
      "\n",
      "   DayOfWeek    DayName  \n",
      "0          3   Thursday  \n",
      "1          4     Friday  \n",
      "2          1    Tuesday  \n",
      "3          2  Wednesday  \n",
      "4          3   Thursday  \n",
      "\n",
      "MCD data:\n",
      "        Date  Open      High       Low     Close  Adj Close   Volume  \\\n",
      "0 1966-07-05   0.0  0.273663  0.267490  0.269547   0.115991   388800   \n",
      "1 1966-07-06   0.0  0.283951  0.267490  0.283951   0.122190   692550   \n",
      "2 1966-07-07   0.0  0.291152  0.271605  0.273663   0.117762  1858950   \n",
      "3 1966-07-08   0.0  0.276749  0.267490  0.276749   0.119090  1239300   \n",
      "4 1966-07-11   0.0  0.283951  0.272634  0.275720   0.118648   656100   \n",
      "\n",
      "   DayOfWeek    DayName  \n",
      "0          1    Tuesday  \n",
      "1          2  Wednesday  \n",
      "2          3   Thursday  \n",
      "3          4     Friday  \n",
      "4          0     Monday  \n",
      "\n",
      "DPZ data:\n",
      "        Date   Open   High    Low  Close  Adj Close    Volume  DayOfWeek  \\\n",
      "0 2004-07-13  14.00  14.10  13.49  13.50   6.144002  14964100          1   \n",
      "1 2004-07-14  13.50  13.55  12.91  13.44   6.116695   2801000          2   \n",
      "2 2004-07-15  13.45  13.85  13.35  13.84   6.298741   1276200          3   \n",
      "3 2004-07-16  13.87  13.90  13.51  13.83   6.294190   1488200          4   \n",
      "4 2004-07-19  13.80  13.80  13.35  13.52   6.153106    966200          0   \n",
      "\n",
      "     DayName  \n",
      "0    Tuesday  \n",
      "1  Wednesday  \n",
      "2   Thursday  \n",
      "3     Friday  \n",
      "4     Monday  \n",
      "\n",
      "PZZA data:\n",
      "        Date      Open      High       Low     Close  Adj Close    Volume  \\\n",
      "0 1993-06-08  2.000000  2.055556  1.888889  1.944444   1.635053  16986600   \n",
      "1 1993-06-09  2.000000  2.222222  1.944444  2.194444   1.845275   2650500   \n",
      "2 1993-06-10  2.250000  2.333333  2.055556  2.111111   1.775201   3562200   \n",
      "3 1993-06-11  2.083333  2.277778  2.083333  2.250000   1.891991   1931400   \n",
      "4 1993-06-14  2.305556  2.333333  2.222222  2.333333   1.962063    730800   \n",
      "\n",
      "   DayOfWeek    DayName  \n",
      "0          1    Tuesday  \n",
      "1          2  Wednesday  \n",
      "2          3   Thursday  \n",
      "3          4     Friday  \n",
      "4          0     Monday  \n",
      "\n",
      "SBUX data:\n",
      "        Date      Open      High       Low     Close  Adj Close     Volume  \\\n",
      "0 1992-06-26  0.328125  0.347656  0.320313  0.335938   0.259137  224358400   \n",
      "1 1992-06-29  0.339844  0.367188  0.332031  0.359375   0.277216   58732800   \n",
      "2 1992-06-30  0.367188  0.371094  0.343750  0.347656   0.268176   34777600   \n",
      "3 1992-07-01  0.351563  0.359375  0.339844  0.355469   0.274203   18316800   \n",
      "4 1992-07-02  0.359375  0.359375  0.347656  0.355469   0.274203   13996800   \n",
      "\n",
      "   DayOfWeek    DayName  \n",
      "0          4     Friday  \n",
      "1          0     Monday  \n",
      "2          1    Tuesday  \n",
      "3          2  Wednesday  \n",
      "4          3   Thursday  \n",
      "\n",
      "WEN data:\n",
      "        Date  Open   High    Low  Close  Adj Close  Volume  DayOfWeek  \\\n",
      "0 1980-05-06   0.0  2.250  2.125  2.125   0.401966     300          1   \n",
      "1 1980-05-07   0.0  2.375  2.250  2.250   0.425611    2000          2   \n",
      "2 1980-05-08   0.0  2.375  2.250  2.375   0.449256    1700          3   \n",
      "3 1980-05-09   0.0  2.375  2.250  2.375   0.449256     700          4   \n",
      "4 1980-05-12   0.0  2.375  2.250  2.250   0.425611    1800          0   \n",
      "\n",
      "     DayName  \n",
      "0    Tuesday  \n",
      "1  Wednesday  \n",
      "2   Thursday  \n",
      "3     Friday  \n",
      "4     Monday  \n",
      "\n",
      "YUM data:\n",
      "        Date      Open      High       Low     Close  Adj Close    Volume  \\\n",
      "0 1997-09-17  5.167146  5.436736  5.167146  5.234543   3.617383  29185406   \n",
      "1 1997-09-18  5.301941  5.414270  5.257009  5.414270   3.741585   6731884   \n",
      "2 1997-09-19  5.403037  5.571531  5.403037  5.436736   3.757111   3440221   \n",
      "3 1997-09-22  5.391804  5.459202  5.380572  5.391804   3.726059   5831072   \n",
      "4 1997-09-23  5.391804  5.414270  5.380572  5.391804   3.726059   2738601   \n",
      "\n",
      "   DayOfWeek    DayName  \n",
      "0          2  Wednesday  \n",
      "1          3   Thursday  \n",
      "2          4     Friday  \n",
      "3          0     Monday  \n",
      "4          1    Tuesday  \n"
     ]
    }
   ],
   "source": [
    "stock_tickers = ['DNUT', 'MCD', 'DPZ', 'PZZA', 'SBUX', 'WEN', 'YUM']\n",
    "\n",
    "# Dictionary to store the dataframes, with stock tickers as keys\n",
    "stock_data = {}\n",
    "\n",
    "for ticker in stock_tickers:\n",
    "    file_path = os.path.join('data/', f'{ticker}.csv')\n",
    "    df = pd.read_csv(file_path)\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    df['DayOfWeek'] = df['Date'].dt.dayofweek\n",
    "    df['DayName'] = df['Date'].dt.day_name()\n",
    "    stock_data[ticker] = df\n",
    "    \n",
    "    print(f'{ticker} data:')\n",
    "    print(stock_data[ticker].head())\n",
    "    print()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-09T17:45:29.918721Z",
     "start_time": "2024-10-09T17:45:29.847548Z"
    }
   },
   "id": "51a6e286eb287b08"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6796 entries, 0 to 6795\n",
      "Data columns (total 9 columns):\n",
      " #   Column     Non-Null Count  Dtype         \n",
      "---  ------     --------------  -----         \n",
      " 0   Date       6796 non-null   datetime64[ns]\n",
      " 1   Open       6796 non-null   float64       \n",
      " 2   High       6796 non-null   float64       \n",
      " 3   Low        6796 non-null   float64       \n",
      " 4   Close      6796 non-null   float64       \n",
      " 5   Adj Close  6796 non-null   float64       \n",
      " 6   Volume     6796 non-null   int64         \n",
      " 7   DayOfWeek  6796 non-null   int32         \n",
      " 8   DayName    6796 non-null   object        \n",
      "dtypes: datetime64[ns](1), float64(5), int32(1), int64(1), object(1)\n",
      "memory usage: 451.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-09T17:45:29.923405Z",
     "start_time": "2024-10-09T17:45:29.917976Z"
    }
   },
   "id": "8001cf0e179eb014"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume',\n       'DayOfWeek', 'DayName'],\n      dtype='object')"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-09T17:45:29.925973Z",
     "start_time": "2024-10-09T17:45:29.923565Z"
    }
   },
   "id": "ba166eca1cf24be9"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "Date         datetime64[ns]\nOpen                float64\nHigh                float64\nLow                 float64\nClose               float64\nAdj Close           float64\nVolume                int64\nDayOfWeek             int32\nDayName              object\ndtype: object"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-09T17:45:29.928693Z",
     "start_time": "2024-10-09T17:45:29.926665Z"
    }
   },
   "id": "cb7642700206195e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Time series data check and missing data analysis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "31dcc6e3fc58ac93"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Confirming dataset is time-based as the dates are unique and ordered chronologically (monotonically increasing) and there are no missing dates"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "927be35555b26339"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "def check_date_properties(df, ticker):\n",
    "    df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')\n",
    "    unique_dates = df['Date'].nunique()\n",
    "    \n",
    "    # Total rows\n",
    "    total_rows = len(df)\n",
    "    \n",
    "    # Check if dates are in chronological order (monotonic increasing)\n",
    "    date_order_correct = df['Date'].is_monotonic_increasing\n",
    "    # Check for missing dates in the time range\n",
    "    date_range = pd.date_range(start=df['Date'].min(), end=df['Date'].max())\n",
    "    \n",
    "    missing_dates = date_range.difference(df['Date'].unique())\n",
    "     # Get day names for missing dates\n",
    "    missing_dates_day_names = missing_dates.to_series().dt.day_name()\n",
    "    \n",
    "    print(f\"\\nTicker: {ticker}\")\n",
    "    print(f\"Unique Dates: {unique_dates}, Total Rows: {total_rows}\")\n",
    "    print(f\"Dates are in chronological order: {date_order_correct}\")\n",
    "    print(f\"Number of missing dates: {len(missing_dates)}\")\n",
    "    if len(missing_dates) > 0:\n",
    "        print(f\"Missing Dates (first 10): {missing_dates[:10]}\")\n",
    "        print(f\"Corresponding Day of the Week (first 10): {missing_dates_day_names[:10].tolist()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-09T17:45:29.931385Z",
     "start_time": "2024-10-09T17:45:29.930310Z"
    }
   },
   "id": "3b396ab321a48634"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ticker: DNUT\n",
      "Unique Dates: 810, Total Rows: 810\n",
      "Dates are in chronological order: True\n",
      "Number of missing dates: 367\n",
      "Missing Dates (first 10): DatetimeIndex(['2021-07-03', '2021-07-04', '2021-07-05', '2021-07-10',\n",
      "               '2021-07-11', '2021-07-17', '2021-07-18', '2021-07-24',\n",
      "               '2021-07-25', '2021-07-31'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "Corresponding Day of the Week (first 10): ['Saturday', 'Sunday', 'Monday', 'Saturday', 'Sunday', 'Saturday', 'Sunday', 'Saturday', 'Sunday', 'Saturday']\n",
      "\n",
      "Ticker: MCD\n",
      "Unique Dates: 14652, Total Rows: 14652\n",
      "Dates are in chronological order: True\n",
      "Number of missing dates: 6610\n",
      "Missing Dates (first 10): DatetimeIndex(['1966-07-09', '1966-07-10', '1966-07-16', '1966-07-17',\n",
      "               '1966-07-23', '1966-07-24', '1966-07-30', '1966-07-31',\n",
      "               '1966-08-06', '1966-08-07'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "Corresponding Day of the Week (first 10): ['Saturday', 'Sunday', 'Saturday', 'Sunday', 'Saturday', 'Sunday', 'Saturday', 'Sunday', 'Saturday', 'Sunday']\n",
      "\n",
      "Ticker: DPZ\n",
      "Unique Dates: 5083, Total Rows: 5083\n",
      "Dates are in chronological order: True\n",
      "Number of missing dates: 2291\n",
      "Missing Dates (first 10): DatetimeIndex(['2004-07-17', '2004-07-18', '2004-07-24', '2004-07-25',\n",
      "               '2004-07-31', '2004-08-01', '2004-08-07', '2004-08-08',\n",
      "               '2004-08-14', '2004-08-15'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "Corresponding Day of the Week (first 10): ['Saturday', 'Sunday', 'Saturday', 'Sunday', 'Saturday', 'Sunday', 'Saturday', 'Sunday', 'Saturday', 'Sunday']\n",
      "\n",
      "Ticker: PZZA\n",
      "Unique Dates: 7878, Total Rows: 7878\n",
      "Dates are in chronological order: True\n",
      "Number of missing dates: 3549\n",
      "Missing Dates (first 10): DatetimeIndex(['1993-06-12', '1993-06-13', '1993-06-19', '1993-06-20',\n",
      "               '1993-06-26', '1993-06-27', '1993-07-03', '1993-07-04',\n",
      "               '1993-07-05', '1993-07-10'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "Corresponding Day of the Week (first 10): ['Saturday', 'Sunday', 'Saturday', 'Sunday', 'Saturday', 'Sunday', 'Saturday', 'Sunday', 'Monday', 'Saturday']\n",
      "\n",
      "Ticker: SBUX\n",
      "Unique Dates: 8117, Total Rows: 8117\n",
      "Dates are in chronological order: True\n",
      "Number of missing dates: 3657\n",
      "Missing Dates (first 10): DatetimeIndex(['1992-06-27', '1992-06-28', '1992-07-03', '1992-07-04',\n",
      "               '1992-07-05', '1992-07-11', '1992-07-12', '1992-07-18',\n",
      "               '1992-07-19', '1992-07-25'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "Corresponding Day of the Week (first 10): ['Saturday', 'Sunday', 'Friday', 'Saturday', 'Sunday', 'Saturday', 'Sunday', 'Saturday', 'Sunday', 'Saturday']\n",
      "\n",
      "Ticker: WEN\n",
      "Unique Dates: 11187, Total Rows: 11187\n",
      "Dates are in chronological order: True\n",
      "Number of missing dates: 5021\n",
      "Missing Dates (first 10): DatetimeIndex(['1980-05-10', '1980-05-11', '1980-05-17', '1980-05-18',\n",
      "               '1980-05-24', '1980-05-25', '1980-05-26', '1980-05-31',\n",
      "               '1980-06-01', '1980-06-07'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "Corresponding Day of the Week (first 10): ['Saturday', 'Sunday', 'Saturday', 'Sunday', 'Saturday', 'Sunday', 'Monday', 'Saturday', 'Sunday', 'Saturday']\n",
      "\n",
      "Ticker: YUM\n",
      "Unique Dates: 6796, Total Rows: 6796\n",
      "Dates are in chronological order: True\n",
      "Number of missing dates: 3069\n",
      "Missing Dates (first 10): DatetimeIndex(['1997-09-20', '1997-09-21', '1997-09-27', '1997-09-28',\n",
      "               '1997-10-04', '1997-10-05', '1997-10-11', '1997-10-12',\n",
      "               '1997-10-18', '1997-10-19'],\n",
      "              dtype='datetime64[ns]', freq=None)\n",
      "Corresponding Day of the Week (first 10): ['Saturday', 'Sunday', 'Saturday', 'Sunday', 'Saturday', 'Sunday', 'Saturday', 'Sunday', 'Saturday', 'Sunday']\n"
     ]
    }
   ],
   "source": [
    "for ticker in stock_tickers:\n",
    "    check_date_properties(stock_data[ticker], ticker)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-09T17:45:30.003563Z",
     "start_time": "2024-10-09T17:45:29.932666Z"
    }
   },
   "id": "9b21e92fb0acbe8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The missing dates correspond to weekends (e.g., Saturdays and Sundays), which is typical for stock market data since stock markets are generally closed on weekends and certain holidays.As the model doesn’t require data for non-trading days, the missing dates can be ignored. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "91f6e1fbf28094c8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The missing dates are expected non-trading days and a final check is done o confirm that no trading days are missing"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e2bf67c0c27f5b85"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ticker: DNUT\n",
      "Dates are in chronological order: True\n",
      "Total Trading Days: 810\n",
      "Unique Dates: 810\n",
      "All trading days are present with no missing dates.\n",
      "\n",
      "Ticker: MCD\n",
      "Dates are in chronological order: True\n",
      "Total Trading Days: 14652\n",
      "Unique Dates: 14652\n",
      "All trading days are present with no missing dates.\n",
      "\n",
      "Ticker: DPZ\n",
      "Dates are in chronological order: True\n",
      "Total Trading Days: 5083\n",
      "Unique Dates: 5083\n",
      "All trading days are present with no missing dates.\n",
      "\n",
      "Ticker: PZZA\n",
      "Dates are in chronological order: True\n",
      "Total Trading Days: 7878\n",
      "Unique Dates: 7878\n",
      "All trading days are present with no missing dates.\n",
      "\n",
      "Ticker: SBUX\n",
      "Dates are in chronological order: True\n",
      "Total Trading Days: 8117\n",
      "Unique Dates: 8117\n",
      "All trading days are present with no missing dates.\n",
      "\n",
      "Ticker: WEN\n",
      "Dates are in chronological order: True\n",
      "Total Trading Days: 11187\n",
      "Unique Dates: 11187\n",
      "All trading days are present with no missing dates.\n",
      "\n",
      "Ticker: YUM\n",
      "Dates are in chronological order: True\n",
      "Total Trading Days: 6796\n",
      "Unique Dates: 6796\n",
      "All trading days are present with no missing dates.\n"
     ]
    }
   ],
   "source": [
    "def check_trading_days(df, ticker):\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "    \n",
    "    # Check if dates are in chronological order and have no gaps between trading days\n",
    "    date_order_correct = df['Date'].is_monotonic_increasing\n",
    "    unique_dates = df['Date'].nunique()\n",
    "    total_rows = len(df)\n",
    "    \n",
    "    print(f\"\\nTicker: {ticker}\")\n",
    "    print(f\"Dates are in chronological order: {date_order_correct}\")\n",
    "    print(f\"Total Trading Days: {total_rows}\")\n",
    "    print(f\"Unique Dates: {unique_dates}\")\n",
    "    \n",
    "    if date_order_correct and unique_dates == total_rows:\n",
    "        print(f\"All trading days are present with no missing dates.\")\n",
    "    else:\n",
    "        print(f\"Some trading days might be missing.\")\n",
    "        \n",
    "for ticker in stock_tickers:\n",
    "    df = stock_data[ticker]\n",
    "    check_trading_days(df, ticker)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-09T17:45:30.019555Z",
     "start_time": "2024-10-09T17:45:30.004196Z"
    }
   },
   "id": "d2f1ff90e97fcddd"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-10-09T17:45:30.021500Z",
     "start_time": "2024-10-09T17:45:30.018716Z"
    }
   },
   "id": "84cbbfeae277d40c"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
